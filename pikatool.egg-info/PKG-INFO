Metadata-Version: 2.2
Name: pikatool
Version: 0.0.1
Summary: A Python package with essential tools for data science.
Home-page: https://github.com/yourusername/pikatool
Author: Manuel De Luzi
Author-email: Manuel De Luzi <your.email@example.com>
License: MIT
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: pandas
Requires-Dist: scipy
Requires-Dist: scikit-learn
Requires-Dist: matplotlib
Requires-Dist: seaborn
Requires-Dist: plotly
Requires-Dist: statsmodels
Requires-Dist: requests
Requires-Dist: jupyter
Requires-Dist: notebook
Requires-Dist: ipywidgets
Requires-Dist: importlib-metadata; python_version < "3.10"
Provides-Extra: dev
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: requires-python

Here's an extended version of the `README.md` with a dedicated **Clustering** section based on the provided script:

```markdown
# Pikatool

Pikatool is a Python package with essential tools for data science, offering various utilities to help with data manipulation, visualization, and machine learning.

## Installation

To install **Pikatool**, simply run:

```bash
pip install pikatool
```

## Usage Example

```python
import pikatool
# Your usage code here
```

## Clustering

### Hierarchical Clustering with `Hclust`

`Hclust` is a class within the package that implements **hierarchical clustering** using **scipy's linkage function**. It allows you to perform clustering with a variety of linkage methods and assign cluster labels to your dataset based on a given criterion.

#### Class: `Hclust`

The `Hclust` class provides functionality to perform **hierarchical clustering** and assign cluster labels using different criteria such as `maxclust`, `inconsistent`, etc.

##### Attributes
- **n_clusters**: `int`
  - The number of clusters to form. This is used in the `predict` method to determine how many clusters should be formed from the hierarchical tree.
- **method**: `str`
  - The linkage method used for clustering (e.g., `'ward'`, `'single'`, `'complete'`).
- **linkage_matrix**: `np.ndarray` or `None`
  - A linkage matrix that encodes the hierarchical clustering. It is computed by the `fit` method.

##### Methods

1. **`__init__(self, n_clusters: int, method: str)`**
   - Initializes the hierarchical clustering model.
   - **Parameters**:
     - `n_clusters` (`int`): The number of clusters to form.
     - `method` (`str`): The linkage method to use for clustering. Valid options include:
       - `"ward"`
       - `"single"`
       - `"complete"`
       - `"average"`
       - `"centroid"`
       - `"median"`
       - `"weighted"`

2. **`fit(self, data: Dataset, dist_metric: str = "euclidean") -> None`**
   - Computes the hierarchical clustering and stores the linkage matrix.
   - **Parameters**:
     - `data` (`Dataset`): The input data for hierarchical clustering (2D NumPy array or Pandas DataFrame).
     - `dist_metric` (`str`, optional): The distance metric used to compute pairwise distances between data points (default is `"euclidean"`).
       - Supported metrics: `"euclidean"`, `"cityblock"`, `"cosine"`, `"hamming"`, etc.
   - **Returns**: None
   - **Raises**: `ValueError` if the input data is not a valid array-like structure or has incompatible dimensions.

3. **`predict(self, criterion: str = "maxclust") -> List[int]`**
   - Assigns cluster labels based on the computed hierarchical structure.
   - **Parameters**:
     - `criterion` (`str`, optional): The method used to form flat clusters from the hierarchical tree (default is `"maxclust"`). The available options are:
       - `"inconsistent"`
       - `"distance"`
       - `"maxclust"`
       - `"monocrit"`
       - `"maxclust_monocrit"`
   - **Returns**: A list of cluster labels, where each entry corresponds to a data point in the original dataset.
   - **Raises**: `ValueError` if the model has not been fitted before calling `predict()`.

#### Example: Using `Hclust` for Hierarchical Clustering

```python
import numpy as np
from pikatool import Hclust

# Sample data
data = np.array([[1, 2], [2, 3], [3, 4], [5, 6], [6, 7]])

# Create an Hclust object with 2 clusters and 'ward' method
clustering_model = Hclust(n_clusters=2, method="ward")

# Fit the model
clustering_model.fit(data)

# Get the cluster labels
cluster_labels = clustering_model.predict()

print("Cluster Labels:", cluster_labels)
```

In this example, we:
1. Create a simple 2D dataset.
2. Instantiate an `Hclust` model with the desired number of clusters (2) and linkage method (`'ward'`).
3. Call the `fit()` method to compute the hierarchical clustering.
4. Use the `predict()` method to get the cluster labels.

---

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request.

## License

MIT License
```

### Explanation:
- The **Clustering** section was added under the main README.
- The **Hclust** class from the provided code is described in detail, including its attributes, methods, and usage.
- An example of using the `Hclust` class is provided to show how it can be used in practice.

This format ensures that users can easily understand how to use the `Hclust` class for hierarchical clustering while also knowing the purpose of each method and parameter. Let me know if you'd like to further expand this or include additional sections!
